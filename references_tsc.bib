% Quick tutorial:
% https://www.overleaf.com/learn/latex/Articles/Getting_started_with_BibLaTeX
% Documentation
% http://mirror.ox.ac.uk/sites/ctan.org/macros/latex/contrib/biblatex/doc/biblatex.pdf

@article{tsc_rev,
    issn        = {0306-4379},
    journal     = {Information Systems},
    pages       = {16},
    volume      = {53},
    publisher   = {Elsevier B.V.},
    year        = {2015},
    title       = {Time-series clustering - A decade review},
    language    = {eng},
    author      = {Aghabozorgi, Saeed and Shirkhorshidi, Ali Seyed and Wah, Teh Ying},
    keywords    = {Computer Science – Analysis ; Gene Expression – Analysis ; Financial Markets – Analysis}
}

@article{ts_data_mining,
    author  = {Philippe Esling, Carlos Agon},
    title   = {Time-series data mining},
    year    = {2012},
    journal = {ACM Cumputing Surveys},
    number  = {45}
}

@article{mixture_gaussian_hmm,
    issn        = {03772217},
    abstract    = {In recent years, large amounts of financial data have become available for analysis. We propose exploring returns from 21 European stock markets by model-based clustering of regime switching models. These econometric models identify clusters of time series with similar dynamic patterns and moreover allow relaxing assumptions of existing approaches, such as the assumption of conditional Gaussian returns. The proposed model handles simultaneously the heterogeneity across stock markets and over time, i.e., time- constant and time-varying discrete latent variables capture unobserved heterogeneity between and within stock markets, respectively. The results show a clear distinction between two groups of stock markets, each one characterized by different regime switching dynamics that correspond to different expected return-risk patterns. We identify three regimes: the so-called bull and bear regimes, as well as a stable regime with returns close to 0, which turns out to be the most frequently occurring regime. This is consistent with stylized facts in financial econometrics.},
    journal     = {European Journal of Operational Research},
    pages       = {852},
    publisher   = {Elsevier Sequoia S.A.},
    year        = {2015},
    title       = {Clustering financial time series: New insights from an extended hidden Markov model},
    language    = {eng},
    address     = {Amsterdam},
    author      = {Dias, Jose and Vermunt, Jeroen and Ramos, Sofia},
    url         = {http://search.proquest.com/docview/1664477966/},
}



@article{financial_tsc_variance_ratio,
    issn        = {1469-7688},
    abstract    = {This study introduces a new distance measure for clustering financial time series based on variance ratio test statistics. The proposed metric attempts to assess the level of interdependence of time series from the point of view of return predictability. Simulation results show that this metric aggregates time series according to their serial dependence structure better than a metric based on the sample autocorrelations. An empirical application of this approach to international stock market returns is presented. The results suggest that this metric discriminates stock markets reasonably well according to size and the level of development. Furthermore, despite the substantial evolution of individual variance ratio statistics, the clustering pattern remains fairly stable across different time periods.},
    journal     = {Quantitative Finance},
    pages       = {2121--2133},
    volume      = {14},
    publisher   = {Routledge},
    number      = {12},
    year        = {2014},
    title       = {Clustering financial time series with variance ratio statistics},
    language    = {eng},
    author      = {Bastos, Joao A and Caiado, Jorge},
    keywords    = {Time Series ; Cluster Analysis ; Variance Ratio Tests ; International Stock Markets ; Business},
    url         = {http://www.tandfonline.com/doi/abs/10.1080/14697688.2012.726736},
}

@article{hmm_pm10_quantifying_impacts,
    issn        = {1352-2310},
    abstract    = {Source apportionment studies use prior exploratory methods that are not purpose-oriented and receptor modelling is based on chemical speciation, requiring costly, time-consuming analyses. Hidden Markov Models (HMMs) are proposed as a routine, exploratory tool to estimate PM10 source contributions. These models were used on annual time series (TS) data from 33 background sites in Spain and Portugal. HMMs enable the creation of groups of PM10 TS observations with similar concentration values, defining the pollutant's regimes of concentration. The results include estimations of source contributions from these regimes, the probability of change among them and their contribution to annual average PM10 concentrations. The annual average Saharan PM10 contribution in the Canary Islands was estimated and compared to other studies. A new procedure for quantifying the wind-blown desert contributions to daily average PM10 concentrations from monitoring sites is proposed. This new procedure seems to correct the net load estimation from deserts achieved with the most frequently used method.},
    journal     = {Atmospheric Environment},
    pages       = {271-281},
    volume      = {117},
    publisher   = {Elsevier Ltd},
    number      = {C},
    year        = {2015},
    title       = {Time series clustering for estimating particulate matter contributions and its use in quantifying impacts from deserts},
    language    = {eng},
    author      = {Gomez-Losada, Alvaro and Pires, Jose Carlos M and Pino-Mejias, Rafael},
    keywords    = {Apportionments ; Hidden Markov Model ; Pm10 ; Sahara ; Engineering ; Environmental Sciences},
}

@article{ghsom_for_finding_optimal_hedge_ratio,
    issn        = {0925-2312},
    abstract    = {In this study, a novel procedure combining computational intelligence and statistical methodologies is proposed to improve the accuracy of minimum-variance optimal hedge ratio (OHR) estimation over various hedging horizons. The time series of financial asset returns are clustered hierarchically using a growing hierarchical self-organizing map (GHSOM) based on the dynamic behaviors of market fluctuation extracted by measurement of variances, covariance, price spread, and their first and second differences. Instead of using original observations, observations with similar patterns in the same cluster and weighted by a resample process are collected to estimate the OHR. Four stock market indexes and related futures contracts, including Taiwan Weighted Index (TWI), Standard $\&$ Poor's 500 Index (S$\&$P 500), Financial Times Stock Exchange 100 Index (FTSE 100), and NIKKEI 255 Index, are adopted in empirical experiments to investigate the correlation between hedging horizon and performance. Results of the experiments demonstrate that the proposed approach can significantly improve OHR decisions for mid-term and long-term hedging compared with traditional ordinary least squares and naive models.},
    journal     = {Neurocomputing},
    pages       = {358--370},
    volume      = {138},
    publisher   = {Elsevier B.V},
    number      = {C},
    year        = {2014},
    title       = {A clustering time series model for the optimal hedge ratio decision making},
    language    = {eng},
    author      = {Hsu, Yu-Chia and Chen, An-Pin},
    keywords    = {Optimal Hedge Ratio ; Financial Time Series ; Ghsom ; Cluster Analysis ; Computer Science},
}

@article{hier_clust_w_state_space_models,
    issn        = {1436-3240},
    abstract    = {Two approaches for clustering of time series have been considered. The first is a novel approach based on a modification of classic state-space modelling while the second is based on functional clustering. For the latter, both k-means and complete-linkage hierarchical clustering algorithms are adopted. The two approaches are compared using a simulation study, and are applied to lake surface water temperature for 256 lakes globally for 5 years of data, to investigate information obtained from each approach.},
    journal     = {Stochastic Environmental Research and Risk Assessment},
    pages       = {463-475},
    volume      = {29},
    publisher   = {Springer Berlin Heidelberg},
    number      = {2},
    year        = {2015},
    title       = {A comparison of clustering approaches for the study of the temporal coherence of multiple time series},
    language    = {eng},
    address     = {Berlin/Heidelberg},
    author      = {Finazzi, Francesco and Haggarty, Ruth and Miller, Claire and Scott, Marian and Fasso, Alessandro},
    keywords    = {State space ; Expectation maximization ; Functional data analysis ; Splines},
}

@article{topology_for_shape_based_tsc,
    issn        = {0957-4174},
    abstract    = {Topology is the branch of mathematics that studies how objects relate to one another for their qualitative structural properties, such as connectivity and shape. In this paper, we present an approach for data clustering based on topological features computed over the persistence diagram, estimated using the theory of persistent homology. The features indicate topological properties such as Betti numbers, i.e., the number of n-dimensional holes in the discretized data space. The main contribution of our approach is enabling the clustering of time series that have similar recurrent behavior characterized by their attractors in phase space and spatial data that have similar scale-invariant spatial distributions, as traditional clustering techniques ignore that information as they rely on point-to-point dissimilarity measures such as Euclidean distance or elastic measures. We present experiments that confirm the usefulness of our approach with time series and spatial data applications in the fields of biology, medicine and ecology.},
    journal     = {Expert Systems With Applications},
    pages       = {6026-6038},
    volume      = {42},
    publisher   = {Elsevier Ltd},
    number      = {15-16},
    year        = {2015},
    title       = {Persistent homology for time series and spatial data clustering},
    language    = {eng},
    author      = {Pereira, Cassio M.M and de Mello, Rodrigo F},
    keywords    = {Data Clustering ; Spatial Data ; Time Series ; Persistent Homology ; Topological Data Analysis ; Computer Science},
}

@article{community_detection_networks_tsc,
    issn        = {0020-0255},
    abstract    = {In this paper, we propose a technique for time series clustering using community detection in complex networks. Firstly, we present a method to transform a set of time series into a network using different distance functions, where each time series is represented by a vertex and the most similar ones are connected. Then, we apply community detection algorithms to identify groups of strongly connected vertices (called a community) and, consequently, identify time series clusters. Still in this paper, we make a comprehensive analysis on the influence of various combinations of time series distance functions, network generation methods and community detection techniques on clustering results. Experimental study shows that the proposed network-based approach achieves better results than various classic or up-to-date clustering techniques under consideration. Statistical tests confirm that the proposed method outperforms some classic clustering algorithms, such as k-medoids, diana, median-linkage and centroid-linkage in various data sets. Interestingly, the proposed method can effectively detect shape patterns presented in time series due to the topological structure of the underlying network constructed in the clustering process. At the same time, other techniques fail to identify such patterns. Moreover, the proposed method is robust enough to group time series presenting similar pattern but with time shifts and/or amplitude variations. In summary, the main point of the proposed method is the transformation of time series from time-space domain to topological domain. Therefore, we hope that our approach contributes not only for time series clustering, but also for general time series analysis tasks.},
    journal     = {Information Sciences},
    pages       = {227--242},
    volume      = {326},
    publisher   = {Elsevier Inc},
    number      = {C},
    year        = {2016},
    title       = {Time series clustering via community detection in networks},
    language    = {eng},
    author      = {Ferreira, Leonardo N and Zhao, Liang},
    keywords    = {Time Series Data Mining ; Time Series Clustering ; Complex Networks ; Community Detection ; Engineering ; Library ; Information Science},
}

@article{ts_stream_2013,
    issn        = {0925-9902},
    abstract    = {The current ability to produce massive amounts of data and the impossibility in storing it motivated the development of data stream mining strategies. Despite the proposal of many techniques, this research area still lacks in approaches to mine data streams composed of multiple time series, which has applications in finance, medicine and science. Most of the current techniques for clustering streaming time series have a serious limitation in their similarity measure, which are based on the Pearson correlation. In this paper, we show the Pearson correlation is not capable of detecting similarities even for classic time series models, such as those by Box and Jenkins. This limitation motivated our proposal to cluster streaming time series based on their generating functions, which is achieved by considering features obtained using descriptive measures, such as Auto Mutual Information, the Hurst Exponent and several others. We present a new tree-based clustering algorithm, entitled TS-Stream, which uses the extracted features to produce partitions in better accordance to the time series generating functions. Experiments with synthetic data sets confirm TS-Stream outperforms ODAC, currently the most popular technique, in terms of clustering quality. Using real financial time series from the NYSE and NASDAQ, we conducted stock trading simulations employing TS-Stream to support the creation of diversified investment portfolios. Results confirmed TS-Stream increased the monetary returns in several orders of magnitude when compared to trading strategies simply based on the Moving Average Convergence Divergence financial indicator.},
    journal     = {Journal of Intelligent Information Systems},
    pages       = {531},
    volume      = {42},
    publisher   = {Springer},
    number      = {3},
    year        = {2014},
    title       = {TS-stream: clustering time series on data streams.},
    language    = {English},
    author      = {Pereira, Cassio M. M. and Mello, Rodrigo F.},
    keywords    = {Securities Trading ; Analysis ; Algorithms ; Analysis},
}

@article{clust_large_datasets_aghabozorg,
    issn        = {1088-467X},
    abstract    = {Time series clustering is a very effective approach in discovering valuable information in various systems such as finance, embedded bio-sensor and genome. However, focusing on the efficiency and scalability of these algorithms to deal with time series data has come at the expense of losing the usability and effectiveness of clustering. In this paper a new multi-step approach is proposed to improve the accuracy of clustering of time series data. In the first step, time series data are clustered approximately. Then, in the second step, the built clusters are split into sub-clusters. Finally, sub-clusters are merged in the third step. In contrast to existing approaches, this method can generate accurate clusters based on similarity in shape in very large time series datasets. The accuracy of the proposed method is evaluated using various published datasets in different domains.},
    journal     = {Intelligent Data Analysis},
    pages       = {793-817},
    volume      = {18},
    number      = {5},
    year        = {2014},
    title       = {Clustering of large time series datasets},
    language    = {eng},
    author      = {Aghabozorgi, Saeed and Wah, Teh},
    keywords    = {Genomes ; Data Processing ; Finance ; Clusters ; Time Series ; Algorithms ; Clustering ; Similarity ; Information Storage, Retrieval, and Analysis (Ci) ; Data Mining ; Clustering ; Time Series ; Large Datasets},
    url = {http://search.proquest.com/docview/1620092812/},
}

@article{garch_robust_tsc,
    issn        = {0165-0114},
    abstract    = {In this paper we propose different robust fuzzy clustering models for classifying heteroskedastic (volatility) time series, following the so-called model-based approach to time series clustering and using a partitioning around medoids procedure. The proposed models are based on a GARCH parametric modeling of the time series, i.e. the unconditional volatility and the time-varying volatility GARCH representation of the time series. We first suggest a timid robustification of the fuzzy clustering. Then, we propose three robust fuzzy clustering models belonging to the so-called metric, noise and trimmed approaches, respectively. Each model neutralizes the negative effects of the outliers in the clustering process in a different manner. In particular, the first robust model, based on the metric approach, achieves its robustness with respect to outliers by taking into account a “robust” distance measure; the second, based on the noise approach, achieves its robustness by introducing a noise cluster represented by a noise prototype; the third, based on the trimmed approach, achieves its robustness by trimming away a certain fraction of outlying time series. The usefulness and effectiveness of the proposed clustering models is illustrated by means of a simulation study and two applications in finance and economics.},
    journal     = {Fuzzy Sets and Systems},
    pages       = {1-28},
    volume      = {305},
    publisher   = {Elsevier B.V},
    year        = {2016},
    title       = {GARCH-based robust clustering of time series},
    language    = {eng},
    author      = {D'Urso, Pierpaolo and De Giovanni, Livia and Massari, Riccardo},
    keywords    = {Heteroskedastic Time Series ; Unconditional and Time-Varying Volatility ; Garch Model ; Fuzzy Partitioning Around Medoids ; Outliers ; Robust Metric ; Noise Cluster ; Trimming ; Volatilities Daily Stocks Returns ; International Stock-Market Volatility Daily Returns ; Mathematics},
}

@article{BSLEX_nonlin_nonstat_tsc,
    issn        = {1387-5841},
    abstract    = {Accurate clustering of time series is a challenging problem for data arising from areas such as financial markets, biomedical studies, and environmental sciences, especially when some, or all, of the series exhibit nonlinearity and nonstationarity. When a subset of the series exhibits nonlinear characteristics, frequency domain clustering methods based on higher-order spectral properties, such as the bispectra or trispectra are useful. While these methods address nonlinearity, they rely on the assumption of series stationarity. We propose the Bispectral Smooth Localized Complex EXponential (BSLEX) approach for clustering nonlinear and nonstationary time series. BSLEX is an extension of the SLEX approach for linear, nonstationary series, and overcomes the challenges of both nonlinearity and nonstationarity through smooth partitions of the nonstationary time series into stationary subsets in a dyadic fashion. The performance of the BSLEX approach is illustrated via simulation where several nonstationary or nonlinear time series are clustered, as well as via accurate clustering of the records of 16 seismic events, eight of which are earthquakes and eight are explosions. We illustrate the utility of the approach by clustering S and P 100 financial returns.},
    journal     = {Methodology and Computing in Applied Probability},
    pages       = {935-955},
    volume      = {19},
    publisher   = {Springer US},
    number      = {3},
    year        = {2017},
    title       = {Clustering Nonlinear, Nonstationary Time Series Using BSLEX},
    language    = {eng},
    address     = {New York},
    author      = {Harvill, Jane and Kohli, Priya and Ravishanker, Nalini},
    keywords    = {Nonlinear time series ; Nonstationary time series ; Time series clustering ; Time-dependent bispectrum ; SLEX},
}

@article{multivariate_tsc_hmm,
    issn        = {1660-4601},
    journal     = {International journal of environmental research and public health},
    abstract    = {In this paper we describe an algorithm for clustering multivariate time series with variables taking both categorical and continuous values. Time series of this type are frequent in health care, where they represent the health trajectories of individuals. The problem is challenging because categorical variables make it difficult to define a meaningful distance between trajectories. We propose an approach based on Hidden Markov Models (HMMs), where we first map each trajectory into an HMM, then define a suitable distance between HMMs and finally proceed to cluster the HMMs with a method based on a distance matrix. We test our approach on a simulated, but realistic, data set of 1,255 trajectories of individuals of age 45 and over, on a synthetic validation set with known clustering structure, and on a smaller set of 268 trajectories extracted from the longitudinal Health and Retirement Survey. The proposed method can be implemented quite simply using standard packages in R and Matlab and may be a good candidate for solving the difficult problem of clustering multivariate time series with categorical variables using tools that do not require advanced statistic knowledge, and therefore are accessible to a wide range of researchers.},
    pages       = {2741-2763},
    volume      = {11},
    number      = {3},
    year        = {2014},
    title       = {Clustering multivariate time series using Hidden Markov Models.},
    language    = {eng},
    author      = {Ghassempour, Shima and Girosi, Federico and Maeder, Anthony},
    keywords    = {Algorithms–Statistics Numerical Data ; Cluster Analysis–Statistics Numerical Data ; Delivery of Health Care–Statistics Numerical Data ; Humans–Statistics Numerical Data ; Markov Chains–Statistics Numerical Data ; Models, Statistical–Statistics Numerical Data ; Multivariate Analysis–Statistics Numerical Data},
    url         = {http://search.proquest.com/docview/1510403562/},
}

@article{copula_fuzzy_tsc_spatial,
    issn        = {2211-6753},
    abstract    = {This paper contributes to the existing literature on the analysis of spatial time series presenting a new clustering algorithm called COFUST, i.e. COpula-based FUzzy clustering algorithm for Spatial Time series. The underlying idea of this algorithm is to perform a fuzzy Partitioning Around Medoids (PAM) clustering using copula-based approach to interpret comovements of time series. This generalisation allows both to extend usual clustering methods for time series based on Pearson’s correlation and to capture the uncertainty that arises assigning units to clusters. Furthermore, its flexibility permits to include directly in the algorithm the spatial information. Our approach is presented and discussed using both simulated and real data, highlighting its main advantages.},
    journal     = {Spatial Statistics},
    pages       = {209--225},
    volume      = {21},
    publisher   = {Elsevier B.V},
    year        = {2017},
    title       = {Copula-based fuzzy clustering of spatial time series},
    language    = {eng},
    author      = {Disegna, Marta and D'urso, Pierpaolo and Durante, Fabrizio},
    keywords    = {Copula ; Fuzzy Clustering ; Partitioning Around Medoids ; Spatial Statistics ; Time Series ; Tourism Economics ; Statistics},
}

@article{shape_feat_mod_tsc_rfa,
    issn        = {1084-0699},
    abstract    = {A regional frequency analysis using L-moments was performed with time series clustering approaches to identify homogeneous regions using dynamic data sets in Northern Cyprus. In this context, the conventional approach, based on station characteristics and different time series clustering approaches, classified as shape-based, feature-based, and model-based, were compared. Hierarchical Ward’s method with the correlation-based similarity measure of the feature-based approach was determined as the best method regarding the results of the jackknife validation procedure, which was performed for assessment of clustering approach uncertainty. Therefore, the cluster analysis ended up with five homogeneous subregions, and according to the goodness-of-fit measure, the Pearson Type III, generalized logistic, and generalized normal distributions were chosen as the best fit for different subregions. The accuracy of the estimated quantiles was evaluated through Monte Carlo simulations and, consequently, the quantiles for different return periods were estimated, which demonstrated spatial consistency in terms of increasing trend from the low-lying Mesaoria Plain toward the north coastal strip, including the Kyrenia Mountains and the Karpass Peninsula.},
    journal     = {Journal of Hydrologic Engineering},
    volume      = {23},
    publisher   = {American Society of Civil Engineers},
    number      = {6},
    year        = {2018},
    title       = {Regional Frequency Analysis of Precipitation Using Time Series Clustering Approaches},
    language    = {eng},
    author      = {Zaifoglu, H and Akintug, B and Yanmaz, A. M},
    keywords    = {Case Studies ; Case Study ; Engineering ; Geography},
}

@article{ica_tsc_sea_level,
    issn        = {0096-3003},
    abstract    = {In this work we propose the use of independent component analysis for clustering time series. Considering different numbers of independent components, the complete linkage method was used to identify groups based on the estimated coefficients of the mixing matrix. The use of independent component analysis not only enables the clustering of time series as also provides us with information about the characteristics common to groups from the analysis of the components. The analysis is exemplified for time series of sea levels in different countries during the period of 26 years. The dendrogram obtained for 2 independent components showed four groups: one contains only Hong Kong, the second is formed by Malaysia and Thailand. The other two groups are formed by Australia, New Zealand and Brazil, Japan, Alaska, Singapore and Norway. We have shown that, using data sea level, the independent component analysis can reveal the underlying structure in the database and is a powerful tool for clustering of time series.},
    journal     = {Applied Mathematics and Computation},
    pages       = {522--527},
    volume      = {243},
    publisher   = {Elsevier Inc},
    number      = {C},
    year        = {2014},
    title       = {Using independent component for clustering of time series data},
    language    = {eng},
    author      = {Safadi, Thelma},
    keywords    = {Cluster Analysis ; Independent Component Analysis ; Sea Level ; Mathematics},
}

@article{apxdist_sax_k_modes,
    issn        = {1016-2364},
    abstract    = {Data in various systems, such as those in finance, healthcare, and business, are stored as time series. As such, interest in time series mining in these areas has surged. Clustering of data is performed as a pre-processing or exploratory approach in many data mining tasks. Time series data sets are often very large, thus, data cannot fit in the main memory for clustering. In this case, dimension reduction is a common solution. However, the cost of data reduction is relatively high because of overlooking the data involved in this process, leading to low-quality clustering. In this paper, we propose a new approach for improving the approximate clustering accuracy of dimensionality reduced time series by discretization approach. A new distance measure is initially introduced. Thereafter, the partitional algorithm that best matches the representation method is proposed.},
    journal     = {Journal of Information Science and Engineering},
    pages       = {207-228},
    volume      = {31},
    number      = {1},
    year        = {2015},
    title       = {Approximate Clustering of Time-Series Datasets using k-Modes Partitioning},
    language    = {eng},
    author      = {Aghabozorgi, Saeed and Wah, Teh},
    keywords    = {Discretization ; Business ; Time Series ; Representations ; Tasks ; Clustering ; Data Reduction ; Approximation ; Information Systems (General) (Ci) ; Data Mining ; Clustering ; Time Series ; Approximation ; Distance Measure ; Dimensionality Reduction},
    url         = {http://search.proquest.com/docview/1686443066/},
}

@article{multivariate_tsc_riemann_manifold,
    issn        = {0013-5194},
    abstract    = {An approach for clustering multivariate time series (MTS) is presented in cases of variable length, noisy data or mix of different type variables. First the covariance matrices are estimated which is used as a feature to represent the MTS, then project the covariance matrices from a Riemannian manifold into a tangent space and finally carry out the clustering based on a distance matrix. In this procedure, a geodesic-based distance is also introduced for measuring the similarity between the MTS samples. The proposed approach on a chaotic MTS with known clustering structure, namely Lorenz system is evaluated.},
    journal     = {Electronics Letters},
    pages       = {1607-1609},
    volume      = {52},
    number      = {19},
    year        = {2016},
    title       = {Clustering multivariate time series based on Riemannian manifold},
    language    = {eng},
    author      = {Sun, Jiancheng},
    keywords    = {Time Series ; Manifolds ; Lorenz System ; Clustering ; Electronics ; Similarity ; Covariance ; Tangents ; Electronic Components and Materials (Ea) ; (An) ; Data Mining ; Pattern Clustering ; Differential Geometry ; Covariance Matrices ; Time Series ; Multivariate Time Series Clustering ; Lorenz System ; Distance Matrix ; Tangent Space ; Geodesic-Based Distance ; Chaotic Mts ; Riemannian Manifold ; Covariance Matrices},
    url         = {http://search.proquest.com/docview/1845816549/},
}

@article{tsc_total_variation_distance,
    issn        = {1180-4009},
    abstract    = {A clustering procedure for time series based on the use of the total variation distance between normalized spectral densities is proposed in this work. The approach is thus based on classifying time series in the frequency domain by consideration of the similarity between their oscillatory characteristics. As an application of this procedure, an algorithm for determining stationary periods for time series of random sea waves is developed, a problem in which changes between stationary sea states is usually slow. The proposed clustering algorithm is compared to several other methods which are also based on features extracted from the original series, and the results show that its performance is comparable to the best methods available, and in some tests, it performs better. This clustering method may be of independent interest.},
    journal     = {Environmetrics},
    pages       = {355-369},
    volume      = {27},
    number      = {6},
    year        = {2016},
    title       = {Time series clustering using the total variation distance with applications in oceanography},
    author      = {Alvarez‐Esteban, Pedro C. and Euan, Carolina and Ortega, Joaquin},
    keywords    = {Spectral Analysis ; Random Sea Waves ; Hierarchical Clustering ; Stationary Periods},
}

@article{temporal_tsc_threshold_ar_models,
    issn        = {0254-5330},
    abstract    = {The primary aim in this study is grouping time series according to the similarity between their data generating mechanisms (DGMs) rather than comparing pattern similarities in the time series trajectories. The approximation to the DGM of each series is accomplished by fitting the linear autoregressive and the non-linear threshold autoregressive models, and outputs of the estimates are used for feature extraction. Threshold autoregressive models are recognized for their ability to represent nonlinear features in time series, such as abrupt changes, time-irreversibility and regime-shifting behavior. The proposed clustering approach is mainly based on feature vectors derived from above-mentioned models estimates. Through the use of the proposed approach, one can determine and monitor the set of co-moving time series variables across the time. The efficiency of the proposed approach is demonstrated through a simulation study and the results are compared with other proposed time series clustering methods. An illustration of the proposed clustering approach is given by application to several commodity prices. It is expected that the process of determining the commodity groups that are time-dependent will advance the current knowledge about temporal behavior and the dynamics of co-moving and coherent prices, and can serve as a basis for multivariate time series analyses. Furthermore, generating a time varying commodity prices index and sub-indexes can become possible. Findings suggested that clusters of the prices series have been affected with the global financial crisis in 2008 and the data generating mechanisms of prices and so the clusters of prices might not be the same across the entire time-period of the analysis.},
    journal     = {Annals of Operations Research},
    pages       = {51-77},
    volume      = {260},
    publisher   = {Springer US},
    number      = {1-2},
    year        = {2018},
    title       = {Temporal clustering of time series via threshold autoregressive models: application to commodity prices},
    language    = {eng},
    address     = {New York},
    author      = {Aslan, Sipan and Yozgatligil, Ceylan and Iyigun, Cem},
    keywords    = {Time series clustering ; Spectral clustering ; Commodity prices},
}

@article{tsc_robust_ar_metric_air_pollution,
    issn        = {0169-7439},
    abstract    = {In this paper, following a fuzzy approach and adopting an autoregressive parameterization, we propose a robust clustering model for classifying time series. In particular, by adopting a fuzzy partitioning around medoids approach, the suggested clustering model is able to define the so-called medoid time series, which is a representative time series of each cluster, and the membership degrees of each time series to the different clusters. The robustness of the proposed clustering model is guaranteed by the adoption of a suitable robust metric for time series, i.e. the so-called exponential distance measure. In this way, the clustering model is able to tolerate the presence of outlier time series in the clustering process. In particular, it is capable of neutralizing and smoothing the disruptive effect of outlier time series, preserving the original clustering structure of the dataset, by assigning to outlier time series approximately the same membership degrees across clusters. To illustrate the usefulness and effectiveness of the suggested time series clustering model, a simulation study and an application to air pollution time series are carried out. Comparison with some existing clustering procedures suggested in the literature shows several advantages of the proposed model.},
    journal     = {Chemometrics and Intelligent Laboratory Systems},
    pages       = {107-124},
    volume      = {141},
    publisher   = {Elsevier B.V},
    year        = {2015},
    title       = {Time series clustering by a robust autoregressive metric with application to air pollution},
    language    = {eng},
    author      = {D'Urso, Pierpaolo and De Giovanni, Livia and Massari, Riccardo},
    keywords    = {Autoregressive Model ; Robust Fuzzy C-Medoids Clustering ; Outliers ; Environmental Chemistry ; Pollutant Concentration ; Nitrogen Monoxide (No) Emissions ; Chemistry},
}

@article{wavelet_multivar_tsc_multiscale_pca,
    issn        = {0360-8352},
    abstract    = {Clustering and pattern recognition from data can be used as means to extract knowledge of a process which may be useful for control, predicting failures and supporting decision making, among other functions. This paper presents a method to recognize patterns in multivariate time series based on a combination of wavelet features, PCA (Principal Component Analysis) similarity metrics and fuzzy clustering. The signal analysis of some process variables is performed based on the Wavelet Transform (WT), and a Multiscale PCA Similarity factor (SPCA) is proposed to consider the distances between objects (multivariate time series) according to a multi-resolution approach. A database extracted from the benchmark Tennessee Eastman (TE) process is used to show the efficiency of the method compared with traditional approaches in a fault detection and diagnosis problem. The clustering using SPCA provides the recognition of a fault pattern which may be useful to support decision-making at the operational level allowing real-time monitoring of failure probability.},
    journal     = {Computers and Industrial Engineering},
    pages       = {144-155},
    volume      = {95},
    publisher   = {Elsevier Ltd},
    year        = {2016},
    title       = {A wavelet-based clustering of multivariate time series using a Multiscale SPCA approach},
    language    = {eng},
    author      = {Barragan, Joao Francisco and Fontes, Cristiano Hora and Embirucu, Marcelo},
    keywords    = {Fuzzy C-Means ; Pattern Recognition ; Wavelet Transform ; Multiscale PCA (Principal Component Analysis) Similarity Factor ; Engineering ; Applied Sciences},
}

@article{stock_price_tsc_regr_trees_som,
    issn        = {0957-4174},
    abstract    = {Predicting the stock market is considered to be a very difficult task due to its non-linear and dynamic nature. Our proposed system is designed in such a way that even a layman can use it. It reduces the burden on the user. The user's job is to give only the recent closing prices of a stock as input and the proposed Recommender system will instruct him when to buy and when to sell if it is profitable or not to buy share in case if it is not profitable to do trading. Using soft computing based techniques is considered to be more suitable for predicting trends in stock market where the data is chaotic and large in number. The soft computing based systems are capable of extracting relevant information from large sets of data by discovering hidden patterns in the data. Here regression trees are used for dimensionality reduction and clustering is done with the help of Self Organizing Maps (SOM). The proposed system is designed to assist stock market investors identify possible profit-making opportunities and also help in developing a better understanding on how to extract the relevant information from stock price data.},
    journal     = {Expert Systems With Applications},
    pages       = {20-36},
    volume      = {70},
    publisher   = {Elsevier Ltd},
    year        = {2017},
    title       = {Clustering stock price time series data to generate stock trading recommendations: An empirical study},
    language    = {eng},
    author      = {Nair, Binoy B and Kumar, P.K. Saravana and Sakthivel, N.R and Vipin, U},
    keywords    = {Stock ; Trading ; Recommender ; Clustering ; Time-Series ; Computer Science},
}

@article{ar_metric_trimmed_fuzzy_tsc_pm10,
    issn        = {0169-7439},
    abstract    = {Air quality measurement relies on the effectiveness of a network of monitoring stations. Monitoring stations collect information about the evolution of air pollutants concentration. If more stations supplies the same information, then some of them could be deemed as redundant. Then, a clustering model for time series is useful to identify stations with similar features. Time series of pollutant concentration can be classified using the autoregressive metric in the framework of standard clustering techniques. A serious drawback is related to the lack of robustness of standard procedures. In this paper, using a partitioning around medoids approach combined with a trimming-based rule, a fuzzy model for cluster time series is proposed. The model provides a robust alternative to standard procedures. Two simulation studies are carried out to evaluate the clustering performance of the proposed clustering model. Finally, an empirical application to real time series of PM10 concentration in the Lazio region is presented and discussed showing the practical usefulness of the proposed approach.},
    journal     = {Chemometrics and Intelligent Laboratory Systems},
    pages       = {15-26},
    volume      = {161},
    publisher   = {Elsevier B.V},
    year        = {2017},
    title       = {Autoregressive metric-based trimmed fuzzy clustering with an application to PM10 time series},
    language    = {eng},
    author      = {D'Urso, Pierpaolo and Massari, Riccardo and Cappelli, Carmela and De Giovanni, Livia},
    keywords    = {Autoregressive Model-Based Fuzzy C-Medoids Clustering ; Robust Clustering ; Outlier Time Series ; Trimming ; Air Pollution ; Particulate Matter ; Chemistry},
}

@article{dependency_aware_tsc_energy_markets,
    issn        = {19961073},
    abstract    = {In this paper, we propose a novel approach for clustering time series, which combines three well-known aspects: a permutation-based coding of the time series, several distance measurements for discrete distributions and hierarchical clustering using different linkages. The proposed method classifies a set of time series into homogeneous groups, according to the degree of dependency among them. That is, time series with a high level of dependency will lie in the same cluster. Moreover, taking into account the nature of the codifying process, the method allows us to detect linear and nonlinear dependences. To illustrate the procedure, a set of fourteen electricity price series coming from different wholesale electricity markets worldwide was analyzed. We show that the classification results are consistent with the characteristics of the electricity markets in the study and with their degree of integration. Besides, we outline the necessity of removing the seasonal component of the price series before the analysis and the capability of the method to detect changes in the dependence level along time.},
    journal     = {Energies},
    pages       = {809},
    volume      = {9},
    publisher   = {MDPI AG},
    number      = {10},
    year        = {2016},
    title       = {Dependency-Aware Clustering of Time Series and Its Application on Energy Markets},
    language    = {eng},
    address     = {Basel},
    author      = {Ruiz-Abellon, Maria and Gabaldon, Antonio and Guillamon, Antonio},
    keywords    = {Time Series Clustering ; Entropy ; Information Theory ; Electricity Markets ; Engineering;},
    url         = {http://search.proquest.com/docview/1831861660/},
}

@article{moar_mpl_tsc,
    issn        = {08997667},
    abstract    = {Mixture of autoregressions (MoAR) models provide a model-based approach to the clustering of time series data. The maximum likelihood (ML) estimation of MoAR models requires evaluating products of large numbers of densities of normal random variables. In practical scenarios, these products converge to zero as the length of the time series increases, and thus the ML estimation of MoAR models becomes infeasible without the use of numerical tricks. We propose a maximum pseudolikelihood (MPL) estimation approach as an alternative to the use of numerical tricks. The MPL estimator is proved to be consistent and can be computed with an EM (expectation-maximization) algorithm. Simulations are used to assess the performance of the MPL estimator against that of the ML estimator in cases where the latter was able to be calculated. An application to the clustering of time series data arising from a resting state fMRI experiment is presented as a demonstration of the methodology.},
    journal     = {Neural Computation},
    pages       = {990},
    publisher   = {MIT Press Journals, The},
    year        = {2017},
    title       = {Maximum Pseudolikelihood Estimation for Model-Based Clustering of Time Series Data},
    language    = {eng},
    address     = {Cambridge},
    author      = {Nguyen, Hien and Mclachlan, Geoffrey and Orban, Pierre and Bellec, Pierre and Janke, Andrew},
    keywords    = {Regression Analysis ; Random Variables ; Estimating Techniques ; Maximum Likelihood Method ; Simulation ; Algorithms ; Nuclear Magnetic Resonance–NMR},
    url         = {http://search.proquest.com/docview/1884823978/},
}

@article{copula_ica_tsc,
    issn        = {0176-4268},
    abstract    = {Independent component analysis (ICA) is a method to recover the original independent variables from the linear transformations of the observations. Most of ICA algorithms are formulated as an optimization of a contrast function which minimizes the cross-dependency among the components. In this paper, we propose an innovative algorithm for performing ICA problem which uses a contrast function based on the Hoeffding’s measure of pairwise dependence. This measure takes its minimum if and only if the random variables are independent, and takes its maximum if and only if one of the variable is a function of the other. Since the Hoeffding’s index is computed based on the rank values rather than the actual values of the data, it is significantly robust to the outliers and performs well even in the presence of noise. The proposed algorithm is evaluated using simulated data. The algorithm is utilized as a pre-processing method for clustering of trends in time series data. This pre-processing technique establish new components from original observations which have adequate information trend of time series. For illustrative purposes, the proposed methodology is applied to clustering of two real data sets involving financial time series.},
    journal     = {Journal of Classification},
    pages       = {230--249},
    volume      = {35},
    publisher   = {Springer US},
    number      = {2},
    year        = {2018},
    title       = {A Copula Based ICA Algorithm and Its Application to Time Series Clustering},
    language    = {eng},
    address     = {New York},
    author      = {Rahmanishamsi, Jafar and Dolati, Ali and Aghabozorgi, Masoudreza},
    keywords    = {Copula ; Hoeffding Measure of dependence ; Independent component analysis ; Time series clustering},
}

@article{tsc_slaughterhouse,
    issn        = {0167-5877},
    abstract    = {A large amount of data is collected routinely in meat inspection in pig slaughterhouses. A time series clustering approach is presented and applied that groups farms based on similar statistical characteristics of meat inspection data over time. A three step characteristic-based clustering approach was used from the idea that the data contain more info than the incidence figures. A stratified subset containing 511,645 pigs was derived as a study set from 3.5 years of meat inspection data. The monthly averages of incidence of pleuritis and of pneumonia of 44 Dutch farms (delivering 5149 batches to 2 pig slaughterhouses) were subjected to 1) derivation of farm level data characteristics 2) factor analysis and 3) clustering into groups of farms. The characteristic-based clustering was able to cluster farms for both lung aberrations. Three groups of data characteristics were informative, describing incidence, time pattern and degree of autocorrelation. The consistency of clustering similar farms was confirmed by repetition of the analysis in a larger dataset. The robustness of the clustering was tested on a substantially extended dataset. This confirmed the earlier results, three data distribution aspects make up the majority of distinction between groups of farms and in these groups (clusters) the majority of the farms was allocated comparable to the earlier allocation (75$\%$ and 62$\%$ for pleuritis and pneumonia, respectively). The difference between pleuritis and pneumonia in their seasonal dependency was confirmed, supporting the biological relevance of the clustering. Comparison of the identified clusters of statistically comparable farms can be used to detect farm level risk factors causing the health aberrations beyond comparison on disease incidence and trend alone.},
    journal     = {Preventive Veterinary Medicine},
    pages       = {64--70},
    volume      = {153},
    publisher   = {Elsevier B.V},
    year        = {2018},
    title       = {A time-series approach for clustering farms based on slaughterhouse health aberration data},
    language    = {eng},
    author      = {Hulsegge, B and de Greef, K.H},
    keywords    = {Meat Inspection Data ; Time Series ; Characteristic-Based Clustering ; Big Data ; Pneumonia ; Pleuritis ; Veterinary Medicine},
}



@article{ambient_air_vape_k_means,
    issn        = {0098-1354},
    abstract    = {A methodology for the robust design of an ambient-air vaporizer under time-series weather conditions is proposed. Two techniques are used to extract representative features in the time-series data. (i) The major trend of a day is rapidly identified by the discrete wavelet transform (DWT), in which a high level of Haar function reflects the trend of a day and drastically reduces the data size. (ii) The K-means clustering method groups the similar features of a year, and the reconstructed time-series dataset extracted by the centroids of clusters represents the weather conditions of a year. The results of the multi-feature-based optimization were compared with non-wavelet based and multi-period optimization by simulation under a year of data. The design structure from the feature extraction shows 22.92$\%$ better performance than the original case and is 12 times more robust in different weather conditions than clustering with raw data.},
    journal     = {Computers and Chemical Engineering},
    pages       = {236--247},
    volume      = {118},
    publisher   = {Elsevier Ltd},
    year        = {2018},
    title       = {Robust design of ambient-air vaporizer based on time-series clustering},
    language    = {eng},
    author      = {Lee, Yongkyu and Na, Jonggeol and Lee, Won Bo},
    keywords    = {Ambient Air Vaporizer ; Wavelet Transform ; K-Means Clustering ; Feature Extraction ; Robust Design ; Global Sensitivity Analysis ; Engineering},
}

@article{mnmf_multivar_tsc_community_detection,
    issn        = {2169-3536},
    abstract    = {In multivariate time series clustering, the inter-similarity across distinct variates and the intra-similarity within each variate pose analytical challenges. Here, we propose a novel multivariate time series clustering method using multi-nonnegative matrix factorization (MNMF) in multi-relational networks. Specifically, a set of multivariate time series is transformed from the time-space domain into a multi-relational network in the topological domain. Then, the multi-relational network is factorized to identify time series clusters. The transformation from the time-space domain to the topological domain benefits from the ability of networks to characterize both the local and global relationships between the nodes, and MNMF incorporates inter-similarity across distinct variates into clustering. Furthermore, to trace the evolutionary trends of clusters, time series is transformed into a dynamic multi-relational network, thereby extending MNMF to dynamic MNMF. Extensive experiments illustrate the superiority of our approach compared with the current state-of-the-art algorithms.},
    journal     = {IEEE Access},
    pages       = {74747--74761},
    volume      = {6},
    publisher   = {IEEE},
    year        = {2018},
    title       = {Clustering Multivariate Time Series Data via Multi-Nonnegative Matrix Factorization in Multi-Relational Networks},
    language    = {eng},
    author      = {Zhou, Lihua and Du, Guowang and Tao, Dapeng and Chen, Hongmei and Cheng, Jun and Gong, Libo},
    keywords    = {Time Series Analysis ; Hidden Markov Models ; Clustering Algorithms ; Heuristic Algorithms ; Transforms ; Market Research ; Feature Extraction ; Multivariate Time Series ; Clustering ; Multi-Relational Network ; Nonnegative Matrix Factorization ; Engineering},
}

@article{fuzzy_c_means_pso_svd,
    issn        = {2322-5211},
    abstract    = {With rapid development in information gathering technologies and access to large amounts of data, we always require methods for data analyzing and extracting useful information from large raw dataset and data mining is an important method for solving this problem. Clustering analysis as the most commonly used function of data mining, has attracted many researchers in computer science. Because of different applications, the problem of clustering the time series data has become highly popular and many algorithms have been proposed in this field. Recently Swarm Intelligence (SI) as a family of nature inspired algorithms has gained huge popularity in the field of pattern recognition and clustering. In this paper, a technique for clustering time series data using a particle swarm optimization (PSO) approach has been proposed, and Pearson Correlation Coefficient as one of the most commonly-used distance measures for time series is considered. The proposed technique is able to find (near) optimal cluster centers during the clustering process. To reduce the dimensionality of the search space and improve the performance of the proposed method, a singular value decomposition (SVD) representation of cluster centers is considered. Experimental results over three popular data sets indicate the superiority of the proposed technique in comparing with fuzzy C-means and fuzzy K-medoids clustering techniques.},
    journal     = {Journal of Artificial Intelligence and Data Mining},
    pages       = {39--46},
    volume      = {3},
    publisher   = {Shahrood University of Technology},
    number      = {1},
    year        = {2015},
    title       = {Fuzzy clustering of time series data: A particle swarm optimization approach},
    language    = {eng},
    author      = {Z. Izakian and M. Mesgari},
    keywords    = {Clustering ; Time Series ; Particle Swarm Optimization ; Singular Value Decomposition ; Pearson Correlation Coefficient},
}

@article{hysteresis_tsc_tensor_decomp,
    issn        = {21682216},
    abstract    = {Many actuators and sensors made by smart materials have hysteresis feature which is a complex nonlinear phenomenon with multivalued mapping. Accurate identification of hysteresis pattern in those sensors and actuators is helpful for improving the modeling and control strategies of the systems. In this paper, a general framework of the pattern clustering of hysteretic time series is developed on the basis of tensor decomposition. First, high-dimensional multivariate data of hysteresis objects are transformed into three-order hysteresis tensors. Then the multilinear principal component analysis (MPCA) is utilized to reduce the dimensionality of hysteresis tensors. Afterward, a novel tensor k-means clustering (CTKmeans) based on tensor distance and cycle variation feature initialization is developed for the clustering of tensor objects. In order to evaluate the performance of the proposed approach, the experiment of hysteresis feature test using polyvinylidene fluoride (PVDF)-based pressure sensors is implemented. The measured high-dimensional hysteresis time series of PVDF successively undergoes the procedures of filtering, segmentation, MPCA dimensionality reduction and CTKmeans clustering. The experimental results show that the MPCA can capture more significant inherent features of hysteresis objects than the principal component analysis (PCA) or the kernel PCA in the dimensionality reduction. In terms of tensor distance and cycle variation feature initialization, the CTKmeans outperforms the random-initialization-based tensor k-means and standard k-means in the clustering of hysteresis tensors. With the tensor decomposition approach of multivariate time series, the hysteresis objects with nonlinear multivalued mapping features can be effectively identified by the combination of MPCA and CTKmeans.},
    journal     = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
    pages       = {993--1004},
    volume      = {48},
    publisher   = {Institute of Electrical and Electronics Engineers Inc.},
    number      = {6},
    year        = {2018},
    title       = {Pattern Clustering of Hysteresis Time Series with Multivalued Mapping Using Tensor Decomposition},
    author      = {He, H. and Tan, Y.},
    keywords    = {Dimensionality Reduction ; Hysteresis ; Pattern Clustering ; Tensor ; Time Series Analysis},
}

@article{comp_many_model_based_tsc_GMM,
    issn        = {1085-7117},
    abstract    = {The desire to group observations generated from multivariate time series is common in many applications with the goal to distinguish not only between differences in the means of individual variables but also changes in their covariances and in the temporal dependence of observations. In this analysis, we compare ten model-based clustering methods in terms of their ability to identify such features under four scenarios in which data are simulated with varying levels of variable and temporal dependence. To consider these methods in a realistic environment, we focus our analysis on wind data, where observations are often strongly correlated in time, and the dependence of variables is known to vary across different regional weather patterns. In particular, we assess each method’s performance when applied to wind data simulated under a realistic two-regime Markov-switching vector autoregressive (VAR) model with a diurnally varying mean. A Gaussian mixture model and a basic Markov-switching model outperform the other methods considered in terms of misclassification rates and number of clusters identified. These two methods and an additional Markov-switching VAR model are then applied to one year of averaged hourly wind data from twenty meteorological stations, and we find that the methods can identify very different features in the data. Supplementary materials accompanying this paper appear on-line.},
    journal     = {Journal of Agricultural, Biological, and Environmental Statistics},
    pages       = {192--217},
    volume      = {20},
    publisher   = {Springer US},
    number      = {2},
    year        = {2015},
    title       = {Assessing the Performance of Model-Based Clustering Methods in Multivariate Time Series with Application to Identifying Regional Wind Regimes},
    language    = {eng},
    address     = {New York},
    author      = {Kazor, Karen and Hering, Amanda},
    keywords    = {Forecasting ; Gaussian mixture models ; -Means ; Markov-switching models ; Nonparametric mixture models},
}

@article{dwt_hac_kmeans_som,
    issn        = {09746846},
    abstract    = {Time series data are commonly used in data mining. Clustering is the most frequently used method for exploratory data analysis. In this paper a model is proposed for similarity search in recent biased time series databases based on different clustering methods. In recent biased analysis, data are much more interesting and useful for predicting future data than old ones. So in our method, we try to reduce data dimensionality by keeping more detail on recent data than older data. Due to “Dimensionality Curse” the original data is mapped into a feature space by means of Vari–segmented Discrete Wavelet Transform 1 and then similarity measurement is performed by applying different clustering methods like Self Organizing Map (SOM), Hierarchical and K-means Clustering. This model is tested using Control Chart Data and the clustering result observed proves that the proposed model is better in grouping similar series under various resolutions.},
    journal     = {Indian Journal of Science and Technology},
    pages       = {189--198},
    volume      = {7},
    number      = {2},
    year        = {2014},
    title       = {Similarity measurement in recent biased time series databases using different clustering methods},
    author      = {Muruga Radha Devi, D. and Thambidurai, P.},
    keywords    = {Clustering ; Dimensionality Reduction ; Discrete Wavelet Transform ; Feature Extraction ; Hierarchical Clustering ; K-Means Clustering ; Self Organizing Map ; Similarity Measurement},
}

@article{xml_dft_delaunay_traingulation,
    issn        = {2152-7385},
    abstract    = {Nowadays exchanging data in XML format become more popular and have widespread application because of simple maintenance and transferring nature of XML documents. So, accelerating search within such a document ensures search engine’s efficiency. In this paper, we propose a technique for detecting the similarity in the structure of XML documents; in the following, we would cluster this document with Delaunay Triangulation method. The technique is based on the idea of representing the structure of an XML document as a time series in which each occurrence of a tag corresponds to a given impulse. So we could use Discrete Fourier Transform as a simple method to analyze these signals in frequency domain and make similarity matrices through a kind of distance measurement, in order to group them into clusters. We exploited Delaunay Triangulation as a clustering method to cluster the d-dimension points of XML documents. The results show a significant efficiency and accuracy in front of common methods.},
    journal     = {Applied Mathematics},
    pages       = {1076--1076},
    volume      = {6},
    number      = {6},
    year        = {2015},
    title       = {A Novel Method for Transforming XML Documents to Time Series and Clustering Them Based on Delaunay Triangulation},
    language    = {eng},
    author      = {Shafieian, Narges},
    keywords    = {Delaunay Triangulation ; Clusters ; Time Series ; Searching ; Extensible Markup Language ; Xml ; Similarity ; Mathematical Analysis ; Mathematics and Computation (Mt) ; Mathematics of Computing (General) (Ci) ; Mathematics and Computation (CE) ; Mathematical and Computer Sciences (General) (Ah)},
    url         = {http://search.proquest.com/docview/1718957579/},
}

@article{svd_birch_tsc_stock_price,
    issn        = {2415-6698},
    abstract    = {With the rapid growth of financial markets, analyzers are paying more attention on predictions. Stock data are time series data, with huge amounts. Feasible solution for handling the increasing amount of data is to use a cluster for parallel processing, and Hadoop parallel computing platform is a typical representative. There are various statistical models for forecasting time series data, but accurate clusters are a pre-requirement. Clustering analysis for time series data is one of the main methods for mining time series data for many other analysis processes. However, general clustering algorithms cannot perform clustering for time series data because series data has a special structure and a high dimensionality has highly co-related values due to high noise level. A novel model for time series clustering is presented using BIRCH, based on piecewise SVD, leading to a novel dimension reduction approach. Highly co-related features are handled using SVD with a novel approach for dimensionality reduction in order to keep co-related behavior optimal and then use BIRCH for clustering. The algorithm is a novel model that can handle massive time series data. Finally, this new model is successfully applied to real stock time series data of Yahoo finance with satisfactory results.},
    journal     = {Advances in Science, Technology and Engineering Systems},
    pages       = {855--864},
    volume      = {2},
    publisher   = {Advances in Science, Technology and Engineering Systems Journal (ASTESJ)},
    number      = {3},
    year        = {2017},
    title       = {A novel model for Time-Series Data Clustering Based on piecewise SVD and BIRCH for Stock Data Analysis on Hadoop Platform},
    language    = {eng},
    author      = {Ibgtc Bowala and Mgnas Fernando},
    keywords    = {Clustering ; Time Series Analysis ; Svd ; Birch ; Hadoop ; Mapreduce},
}

@article{road_grade_china_pca_kmeans,
    issn        = {1002-0063},
    abstract    = {With the increasing number of vehicles in large- and medium-sized cities challenges in urban traffic management, control, and road planning are being faced. Taxi GPS trajectory data is a novel data source that can be used to study the potential dynamic traffic characteristics of urban roads, and thus identify locations that show a notable lack of road planning. Considering that road traffic characteristics on their own are insufficient for a comprehensive understanding of urban traffic, we develop a road traffic characteristic time series clustering model to analyze the relationship between urban road traffic characteristics and road grade based on existing taxi trajectory data. We select the main urban area of Nanjing as our study area and use the taxi trajectory data of a single month for evaluating our method. The experiments show that the clustering model exhibit good performance and can be successfully used for road traffic characteristic classification. Moreover, we analyze the correlation between traffic characteristics and road grade to identify road segments with planning designs that do not match the actual traffic demands.},
    journal     = {Chinese Geographical Science},
    pages       = {1048--1060},
    volume      = {28},
    publisher   = {Science Press},
    number      = {6},
    year        = {2018},
    title       = {Relationship Between Urban Road Traffic Characteristics and Road Grade Based on a Time Series Clustering Model: A Case Study in Nanjing, China},
    language    = {eng},
    address     = {Heidelberg},
    author      = {Wang, Jiechen and Wu, Jiayi and Ni, Jianhua and Chen, Jie and Xi, Changbai},
    keywords    = {time series clustering ; temporal characteristics of road speed ; taxi trajectory data ; urban computation ; machine-learning},
}

@article{fragmented_periodogram,
    issn        = {18625347},
    abstract    = {We propose and study a new frequency-domain procedure for characterizing and comparing large sets of long time series. Instead of using all the information available from data, which would be computationally very expensive, we propose some regularization rules in order to select and summarize the most relevant information for clustering purposes. Essentially, we suggest to use a fragmented periodogram computed around the driving cyclical components of interest and to compare the various estimates. This procedure is computationally simple, but able to condense relevant information of the time series. A simulation exercise shows that the smoothed fragmented periodogram works in general better than the non-smoothed one and not worse than the complete periodogram for medium to large sample sizes. We illustrate this procedure in a study of the evolution of several stock markets indices. We further show the effect of recent financial crises over these indices behaviour.},
    journal     = {Advances in Data Analysis and Classification},
    pages       = {1--30},
    publisher   = {Springer Nature B.V.},
    year        = {2019},
    title       = {A fragmented-periodogram approach for clustering big data time series},
    language    = {eng},
    address     = {Heidelberg},
    author      = {Caiado, Jorge and Crato, Nuno and Poncela, Pilar},
    url         = {http://search.proquest.com/docview/2239964127/},
}

@article{auto_encoder_many_tsc_algorithms,
    issn        = {0306-2619},
    abstract    = {Structured data of all sensors and actuators are a requirement for decisions about control strategies and efficiency optimization in Building Automation. In practice, the analysis of data is a challenging and time-consuming task. In previous work, it has been demonstrated that classification algorithms may reach high classification accuracies when applied to building data. However, supervised algorithms require labelled training data sets and a predefined classes, and depend highly on the selection of input features. In this paper, we investigate how unsupervised machine learning techniques can be used to tackle both the problem of classification of time series as well as the problem of feature selection. We present a selection of the most promising algorithms and apply them on data extracted from the E.ON Energy Research Center. We then investigate the use of an unsupervised feature extraction compared to the statistical features used in previous literature by comparing the results of the classification on different data sets.Our investigations show that the unsupervised methods we apply to not find data clusters that represent the pre-defined class labels. They, however, are able to find groups of similar data points, showing that clustering is in general possible and that the time series have distinguishable properties. We also see a more robust performance of the classification algorithms when unsupervised feature extraction is used. The results of this paper show that unsupervised machine learning algorithms cannot generally mitigate the issue of missing training data. However, they can improve supervised classification by providing a more robust set of features compared to manual selection. From the clusters that where found we can derive insights about the properties of the time series, that allow us to make a better assessment which information that can be extracted using data-driven algorithms.},
    journal     = {Applied Energy},
    pages       = {1337--1345},
    volume      = {238},
    publisher   = {Elsevier Ltd},
    year        = {2019},
    title       = {A time series clustering approach for Building Automation and Control Systems},
    language    = {eng},
    author      = {Bode, Gerrit and Schreiber, Thomas and Baranski, Marc and Müller, Dirk},
    keywords    = {Big Data ; Unsupervised ; Machine Learning ; Building Automation and Control ; Time Series Clustering ; Feature Extraction ; Engineering ; Environmental Sciences},
}

@article{load_tsc_state_space_model,
    issn        = {0306-2619},
    abstract    = {Clustering of electricity customers supports effective market segmentation and management. The literature suggests the clustering of residential customers by their load characteristics. The key challenge is the application of appropriate processes to reduce the extreme dimensionality of load time series to facilitate unique clusters. Time feature extraction is a potential remedy, however, it is limited by the type of noisy, patchy, and unequal time-series common in residential datasets. In this paper we propose a strategy to alleviate these limitations by converting any types of load time series into map models that can be readily clustered. This also results in higher cluster distinction and robustness against noise compared to a baseline feature-based approach. A large dataset of residential electricity customers is used to confirm the outcomes as measured by a number of analytical and industrial metrics. The experiment with 12 clusters results in around 61$\%$ distinction, improved coincidence factor by around 6.75$\%$ relative to a random grouping, and robustness of around 59$\%$ against the applied noise.},
    journal     = {Applied Energy},
    pages       = {11--24},
    volume      = {237},
    publisher   = {Elsevier Ltd},
    year        = {2019},
    title       = {Clustering of residential electricity customers using load time series},
    language    = {eng},
    author      = {Motlagh, Omid and Berry, Adam and O'Neil, Lachlan},
    keywords    = {Electricity Consumption ; Time Series Clustering ; Unequal Time Series ; Load Profile ; Engineering ; Environmental Sciences},
}

@article{structure_damage_ar_fuzzy_c_means,
    issn        = {1369-4332},
    abstract    = {Time-series methods have been popularly used for damage identification of civil structure because of its output-only and non-model approach. Since the existence of structural damage is usually vague and not focussed on any particular time point, the switches in damage patterns from one time state to another are necessary to be treated in a fuzzy way. This article develops a damage identification method based on the fuzzy clustering of time-series model. The changes of model coefficients of time-series model are proposed to indicate the undamaged and damaged states by the fuzzy c-means clustering algorithm. The residual errors of time-series model are used to identify the damage location and damage severity. The proposed method is applied to an experimental segment lining and a numerical study of a practical bridge. The results verify that the proposed method is accurate and efficient to detect the structural damage location and severity. Since the computational process of time-series model and fuzzy clustering require low computational cost, the proposed data-based damage identification method is applicable to the online structural health monitoring system of large-scale civil structures.},
    journal     = {Advances in Structural Engineering},
    pages       = {868--881},
    volume      = {22},
    publisher   = {SAGE Publications},
    number      = {4},
    year        = {2019},
    title       = {Fuzzy clustering of time-series model to damage identification of structures},
    language    = {eng},
    address     = {London, England},
    author      = {Zeng, Yongping and Yan, Yongyi and Weng, Shun and Sun, Yanhua and Tian, Wei and Yu, Hong},
    keywords    = {Auto-Regressive Model ; Damage Identification ; Fuzzy Clustering ; Structural Health Monitoring ; Time Series ; Engineering},
}

@article{fstar_hac_tsc,
    issn        = {1862-5347},
    abstract    = {The STAR model is widely used to represent the dynamics of a certain variable recorded at several locations at the same time. Its advantages are often discussed in terms of parsimony with respect to space-time VAR structures because it considers a single coefficient for each time and spatial lag. This hypothesis can be very strong; we add a certain degree of flexibility to the STAR model, providing the possibility for coefficients to vary in groups of locations. The new class of models (called Flexible STAR–FSTAR) is compared to the classical STAR and the space-time VAR by simulations and an application.},
    journal     = {Advances in Data Analysis and Classification},
    pages       = {175--199},
    volume      = {13},
    publisher   = {Springer Berlin Heidelberg},
    number      = {1},
    title       = {Clustering space-time series: FSTAR as a flexible STAR approach},
    language    = {eng},
    address     = {Berlin/Heidelberg},
    author      = {Otranto, Edoardo and Mucciardi, Massimo},
    keywords    = {Clustering ; Forecasting ; Space–time models ; Spatial weight matrix},
}

@article{multivariate_tsc_common_pca,
    issn        = {0925-2312},
    abstract    = {Time series clustering is often applied to pattern recognition and also as the basis of the tasks in the field of time series data mining including dimensionality reduction, feature extraction, classification and visualization. Due to the high dimensionality of multivariate time series and most of the previous work concentrating on univariate time series clustering, a novel method which is based on common principal component analysis, is proposed to achieve multivariate time series clustering more fast and accurately. It is inspired by the traditional clustering method K-Means and can construct a common projection axes as prototype of each cluster. Moreover, the reconstruction error of each multivariate time series projected on the corresponding common projection axes are used to reassign the member of the cluster. The detailed algorithm of the proposed method Mc2PCA is given and the time complexity is analyzed, which shows that the proposed method is very fast and its time complexity is linear to the number of multivariate time series objects. Unlike the traditional methods, the proposed method considers the relationship among variables and the distribution of the original data values of multivariate time series. The experimental results in the various datasets demonstrate that Mc2PCA is superior to the traditional methods for multivariate time series clustering.},
    journal     = {Neurocomputing},
    pages       = {239--247},
    volume      = {349},
    publisher   = {Elsevier B.V},
    year        = {2019},
    title       = {Multivariate time series clustering based on common principal component analysis},
    language    = {eng},
    author      = {Li, Hailin},
    keywords    = {Multivariate Time Series ; Clustering Analysis ; Common Principal Component Analysis ; Data Mining ; Dimensionality Reduction ; Computer Science},
}

@article{tensor_multi_elastic_kernel_tsc,
    issn        = {1041-4347},
    abstract    = {Time series clustering has attracted growing attention due to the abundant data accessible and extensive value in various applications. The unique characteristics of time series, including high-dimension, warping, unequal length, and the choice of elastic measure, pose challenges for the present clustering algorithms, most of which take into account only part of these difficulties. In this paper, we make an effort to simultaneously address all aforementioned issues in time series clustering under a unified multiple kernels clustering (MKC) framework. Specifically, we first implicitly map the raw time series space into multiple kernel spaces via elastic distance measure functions. In such high-dimensional spaces, we resort to the tensor constraint based self-representation subspace clustering approach, involving in the self-paced learning paradigm, to explore the essential low-dimensional structure of the data, as well as the high-order complementary information from different elastic kernels. The proposed approach can be extended to more challenging multivariate time series clustering scenario in a direct but elegant way. Extensive experiments on 41 univariate and 10 multivariate time series datasets, which are widely used and publicly available, demonstrate the significant superiority of the proposed approach beyond the baseline and several state-of-the-art MKC methods.},
    journal     = {IEEE Transactions on Knowledge and Data Engineering},
    pages       = {1--1},
    publisher   = {IEEE},
    year        = {2019},
    title       = {Tensor Multi-Elastic Kernel Self-Paced Learning for Time Series Clustering},
    language    = {eng},
    author      = {Tang, Yongqiang and Xie, Yuan and Yang, Xuebing and Niu, Jinghao and Zhang, Wensheng},
    keywords    = {Kernel ; Time Series Analysis ; Time Measurement ; Clustering Algorithms ; Optimization ; Task Analysis ; Time Series Clustering ; Multiple Kernels Clustering ; Self-Paced Learning ; Tensor Optimization ; Engineering ; Computer Science},
}



