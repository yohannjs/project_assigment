\documentclass[18pt, a3paper, portrait]{tikzposter}
\usepackage[utf8]{inputenc}
\usepackage{blindtext}
\usepackage{comment}
\usepackage{amsmath,amsfonts,amsthm,bm} % Math packages 
\usepackage{tikz} % To make cool diagrams
\usepackage{booktabs} % For fancy tables

\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}} % Something about allowing more space between rows in fancy tables.

\makeatletter
\def\title#1{\gdef\@title{\scalebox{\TP@titletextscale}{%
\begin{minipage}[t]{\linewidth}
\centering
#1
\par
\vspace{0.5em}
\end{minipage}%
}}}
\makeatother

\title{Whole-series Time-series Clustering Techniques}
\author{Yohann Jacob Sandvik}
\date{\today}
\institute{Institute of Electronic Systems - NTNU}
 
\usetheme{Envelope}
 
\begin{document}
 
\maketitle 
%% Overview of whole-series time-series clustering techniques
\begin{columns}
    \column{0.7}
    \block{Overview of Whole-series Time-series Clustering Techniques}
    {
        \begin{itemize}
            \item There are three types of time-series clustering, \textit{whole-series time-series clustering}, \textit{subsequence time-series clustering} and \textit{time-point time-series clustering}.
            \item In this review we will only consider work using whole-series time-series clustering.
            \item Whole series time-series clustering can broadly be divided into three main approaches. The raw-data based approach, the feature-based approach and the model based approach.
            \item When clustering raw time series the majority of the work goes into selection of similarity metric and clustering algorithm, and one clusters the time series with regard to similarity in time or similarity in shape.
            \item In the feature-based approach one also clusters time series with regard to similarity in time, and shape, but the work is somewhat shifted away from choice of similarity metric and over to choice of representation.
            \item In the model-based approach the goal is most often to cluster time series with regard to the underlying data generating process. The underlying assumption being that two time series that appear different might still have been generated by the same process.
        \end{itemize}
    }
 
    \column{0.3}
    \block{~}
    {
        \begin{tikzfigure}
            \includegraphics[width=0.25\textwidth]{images/tsc_appraches.png}
        \end{tikzfigure}
    }
\end{columns}

%% Explanation of the most common models
\begin{columns}
    \column{0.33}
    \block{ARMA models}
    {
        \begin{equation}
            X_t - \phi_1 X_{t-1} - ... - \phi_p X_{t-p} = Z_{t} + \theta_1 Z_{t-1} + ... + \theta_q Z_{t-q}
        \end{equation}
    }

    \column{0.33}
    \block{Hidden Markov Models}
    {
        Transition probabilities.
        \begin{equation}
            \begin{split}
                p_{ij}  &= P(X_n = i | X_{n-1} = i_{n-1},..., X_{0} = i_{0}) \\
                        &= P(X_n = i | X_{n-1} = i_{n-1})      
            \end{split}
            \label{eq:markov_property}
        \end{equation}
        Hidden states with emmission probabilities.
        \begin{equation}
            P(S = s | X = j)
        \end{equation}
    }

    \column{0.33}
    \block{PCA and ICA}
    {
        PCA and ICA are both ways of projecting the input matrix onto a reduced feature space.
        In PCA one finds the principal components that are the eigenvectors of the covariance matrix if the input vectors.
        In ICA one assumes that the matrix of observed variables is a linear combination of mutually independent variables.
        Hence, one tries to reconstruct a set of variables that are as ''mutually independent'' as possible.

    }
\end{columns}

%% Representation results
\begin{columns}
    \column{0.5}
    \block{Feature-based representations}
    {
        he
    }
 
    \column{0.5}
    \block{Model-based representations}
    {
        Here,  
        \vspace{4cm}
    }
\end{columns}

%% Clustering algorithms
\begin{columns}
    \column{0.25}
    \block{K-means}
    {
        Here,  
        \vspace{4cm}
    }

    \column{0.25}
    \block{Fuzzy C-means}
    {
        Here,  
        \vspace{4cm}
    }

    \column{0.25}
    \block{Hierarchical Clustering}
    {
        Here,  
        \vspace{4cm}
    }

    \column{0.25}
    \block{Expectation Maximization}
    {
        Here,  
        \vspace{4cm}
    }
\end{columns}

%% Clustering algorithms results
\begin{columns}
    \column{0.7}
    \block{Clustering Algorithms}
    {
        Text and more text. I want to add a new line. \newline
        Did it work?
        \vspace{4cm}
    }
 
    \column{0.3}
    \block{~}
    {
        Here,  
        \vspace{4cm}
    }
\end{columns}

%% Discussion 
\block{Discussion}
{
    THIS IS THE DISCUSSION, OR IS IT?
}
\end{document}


